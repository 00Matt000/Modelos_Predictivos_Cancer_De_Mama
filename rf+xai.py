# -*- coding: utf-8 -*-
"""RF+XAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tHqqOJClXybUzigA6_YCQYy9eZgjQOU0

#Modelo predictivo de diagnosticos de cancer de mama.
###Dataset utilizado: "Breast Cancer Dataset" de la plataforma Kaggle (uso plublico).
###Algoritmo de clasificación: Random Forest (RF).
###Tecnicas de inteligencia artificial explicativa (XAI): SHAP y LIME.

###Instalación de librerias necesarias para el uso de XAI
"""

!pip install shap
!pip install lime

"""###Importación de las librerias necesarias para el modelo."""

import os
import kagglehub

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import shap
shap.initjs()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, accuracy_score, classification_report
from lime.lime_tabular import LimeTabularExplainer

"""###Exportación del dataset"""

#Se guarda la ruta de acceso al dataset.
file_path = '/content/drive/MyDrive/breast-cancer.csv'

#Se lee y guarda el dataset dentro de la variable 'df'.
df = pd.read_csv(file_path)

"""###Preprocesado de los datos."""

#Se crea la variable 'le' para luego usarla para convertir datos categoricos a numericos.
le = LabelEncoder()

#Se elimina la columna 'id' ya que no es relevante para la predicción.
df.drop(["id"], axis=1, inplace=True)

#Se selecciona la columna de 'diagnosis' para convertir sus datos de categoricos a numericos.
df["diagnosis"] = le.fit_transform(df["diagnosis"])

#Se imprimen los datos para confirmar los cambios.
print(df.head())

#Se imprime la cantidad de filas y columnas dentro del dataset luego de los cambios.
df.shape

"""###Busqueda de datos nulos."""

#Se busca si existen datos nulos dentro de las columnas.
df.isnull().sum()

"""###Visualización del contenido de 'diagnosis'."""

#Se guarda la columna 'diagnosis' como objetivo
target = df["diagnosis"]

#Se guardan los datos de la columna.
data = target.value_counts()

#Se genera un grafico de barra para visualizar la cantidad de casos de cancer maligno (1) y benigno (0)
data.plot(kind='bar')
plt.show()

#Entrega el numero de datos correspondiente a cada valor de la columna.
target.value_counts()

"""###Correlación entre las caracteristicas y 'diagnosis'."""

#Se guarda la correlación existente entre las variables y 'diagnosis'.
corr = df.corr()['diagnosis'].sort_values(ascending=False)

#Se imprime la correlación de las variables en orden descendente.
print(corr)

"""###Visualización de la correlación de las caracteristicas."""

#Se establecen los atributos del grafico (heatmap) de correlación.
plt.figure(figsize=(14,10))
sns.heatmap(df.corr(), cmap='coolwarm', annot=True, fmt='.1f', cbar=True, mask=np.triu(np.ones_like(df.corr(), dtype=bool)))
plt.title("Correlation Heatmap")
plt.show()

"""###Descarte de caracteristicas con alta correlación."""

#Se calcula la matriz de correlación
corr_matrix = df.corr().abs()

#Se aplica una mascara para seleccionar solo el triangulo superior de la matriz de correlación.
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

#Se buscan las caracteristicas con una correlación mayor a 0.8 .
to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]

#Se descartan las caracteristicas con una alta correlación.
df_reduced = df.drop(columns=to_drop)

#Se imprime tanto el dataframe original como el nuevo.
print("DataFrame original:")
print(df.shape)
print("\nDataFrame tras descartar las caracteristicas con alta correlación:")
print(df_reduced.shape)

"""###Preparación de los datos de entrenamiento y prueba."""

#Se selecciona la columna 'diagnosis' del dataframe recortado para el valor y.
y = df_reduced["diagnosis"]

#Se seleccionan todas las demas caracteristicas salvo 'diagnosis'.
X = df_reduced.drop(["diagnosis"], axis=1)

#Se establecen los datos de entrenamiento y prueba.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Se crea la variable 'scaler' para luego usarla para normalizar las caracteristicas.
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Se imprimen los datos y columnas de entrenamiento y prueba.
print("x_train shape: ", X_train.shape)
print("x_test shape: ", X_test.shape)
print("y_train shape: ", y_train.shape)
print("y_test shape: ", y_test.shape)

"""###Construcción del modelo y busqueda de sus hiperparametros."""

#Definimos el modelo base.
rf_model = RandomForestClassifier(random_state=42)

#Definir la grilla de hiperparámetros.
param_grid = {
    'n_estimators': [50, 100, 200, 250, 300, 350],
    'min_samples_leaf': [1, 2, 3, 4, 5, 6],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'max_features': ['auto', 'sqrt', 'log2']
}



#Configuración del GridSearchCV.
grid_search = GridSearchCV(
    estimator=rf_model,
    param_grid=param_grid,
    cv=10,
    scoring='accuracy',
    n_jobs=-1,  # usa todos los núcleos.
    verbose=2
)

#Ejecutamos la búsqueda.
grid_search.fit(X_train, y_train)

#Se guarda el mejor modelo.
best_model = grid_search.best_estimator_

"""###Mejores hiperparametros para el modelo predictivo."""

#Se imprimen los mejores parametros encontrados por el GridSearchCV
print("Mejores hiperparámetros:")
print(grid_search.best_params_)

"""###Precision de las predicciones del modelo"""

#Se realizan predicciones sobre el conjunto de prueba (X_test) usando el mejor modelo.
y_pred = best_model.predict(X_test)

#Se imprime la precisión del modelo y el reporte.
print("Accuracy en el conjunto de prueba:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""###Matriz de confusión del modelo."""

# Matriz de confusión
labels = np.unique(y)
cm = confusion_matrix(y_test, y_pred, labels=labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot()
plt.title("Matriz de confusión")
plt.show()

"""###Visualización del area bajo la curva del modelo."""

#Se grafica el area bajo la curva del modelo.
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.title("Receiver Operating Characteristic (ROC)", fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""###Sensibilidad y especificidad del modelo."""

#Calcular sensibilidad y especificidad desde la matriz de confusión
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

sensibilidad = tp / (tp + fn)
especificidad = tn / (tn + fp)

#Se Imprimen la sensibilidad y especificidad
print(f"Sensibilidad (Recall): {sensibilidad:.2f}")
print(f"Especificidad: {especificidad:.2f}")

"""###Explicador y valores SHAP."""

#Se crea un 'explicador' utilizando el 'shap.TreeExplainer' con el mejor modelo.
explainer = shap.TreeExplainer(best_model)

#Se calculan los valores SHAP del conjunto de prueba.
shap_values = explainer.shap_values(X_test)

"""###Grafico general de valores SHAP (caso Benigno)."""

#Se realiza una grafica general de los valores SHAP para el caso de que sea 0 (Benigno).
shap.summary_plot(shap_values[:, :, 0], X_test, feature_names=X.columns)

"""###Grafico general de valores SHAP (caso Maligno)."""

#Se realiza una grafica general de los valores SHAP para el caso de que sea 1 (Maligno).
shap.summary_plot(shap_values[:, :, 1], X_test, feature_names=X.columns)

"""###Grafico de dependencia entre 'concavity_worst' y 'radius_mean' para caso Benigno."""

#Se genera una grafica de dependencia entre la caracteristica 'concavity_worst' y 'radius_mean' para caso Benigno.
shap.dependence_plot("concavity_worst", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'concavity_worst' y 'radius_mean' para caso Maligno."""

#Se genera una grafica de dependencia entre la caracteristica 'concavity_worst' y 'radius_mean' para caso Maligno.
shap.dependence_plot("concavity_worst", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'concavity_mean' y 'radius_mean' para caso Benigno."""

shap.dependence_plot("concavity_mean", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'concavity_mean' y 'radius_mean' para caso Maligno."""

shap.dependence_plot("concavity_mean", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'radius_se' y 'radius_mean' para caso Benigno."""

shap.dependence_plot("radius_se", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'radius_se' y 'radius_mean' para caso Maligno."""

shap.dependence_plot("radius_se", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'texture_mean' y 'radius_mean' para caso Benigno."""

shap.dependence_plot("texture_mean", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'texture_mean' y 'radius_mean' para caso Maligno."""

shap.dependence_plot("texture_mean", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'symmetry_worst' y 'radius_mean' para caso Benigno."""

shap.dependence_plot("symmetry_worst", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'symmetry_worst' y 'radius_mean' para caso Maligno."""

shap.dependence_plot("symmetry_worst", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'fractal_dimension_se' y 'radius_mean' para caso Benigno."""

shap.dependence_plot("fractal_dimension_se", shap_values[:, :, 0], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de dependencia entre 'fractal_dimension_se' y 'radius_mean' para caso Maligno."""

shap.dependence_plot("fractal_dimension_se", shap_values[:, :, 1], X_test, interaction_index="radius_mean", feature_names=X.columns)

"""###Grafico de fuerza del caso 14 (Benigno)."""

#Se realiza un grafico de fuerza en relación con el caso 14 (caso benigno).
shap.plots.force(explainer.expected_value[0], shap_values[14,:, 0], X_test[14, :], matplotlib = True, feature_names=X.columns )

"""###Grafico de fuerza del caso 11 (Maligno)."""

#Se realiza un grafico de fuerza en relación con el caso 11 (caso maligno).
shap.plots.force(explainer.expected_value[0], shap_values[11,:, 1], X_test[19, :], matplotlib = True, feature_names=X.columns )

"""###Grafico de decisiones del caso 14 (Benigno).

"""

#Se realiza un grafico de decisiones del caso 14 (Caso benigno).
shap.decision_plot(explainer.expected_value[0], shap_values[14,:, 0], X_test[14, :], X.columns.tolist())

"""###Grafico de decisiones del caso 11 (Maligno).

"""

#Se realiza un grafico de decisiones del caso 11 (Caso benigno).
shap.decision_plot(explainer.expected_value[0], shap_values[11,:, 1], X_test[11, :], X.columns.tolist()) # Convert X.columns to a list

"""###Grafico LIME de influencia a nivel local."""

# Se definen los nombres de las clases según el problema de clasificación (por ejemplo, cáncer benigno o maligno)
class_names = ['Benigno', 'Maligno']

# Se obtiene la lista de nombres de características a partir del conjunto de entrenamiento
feature_names = list(X.columns)

# Se crea el explicador LIME configurado para problemas de clasificación tabular.
# Este explicador utilizará las instancias de entrenamiento para generar explicaciones locales.
explainer = LimeTabularExplainer(X_train,
                                 feature_names=feature_names,
                                 class_names=class_names,
                                 mode='classification')

# Identificación de índices en el conjunto de prueba para cada clase
# Aquí se asume que el valor 1 representa la clase "Maligno" y 0 la clase "Benigno"
malignant_indices = y_test[y_test == 1].index
benign_indices = y_test[y_test == 0].index

# === Explicación de una instancia de la clase "Maligno" ===

# Se filtran los índices para asegurarse de que estén dentro del rango válido de X_test
valid_malignant_indices = malignant_indices[malignant_indices < len(X_test)]

# Se selecciona la primera instancia válida de la clase "Maligno"
i_malignant = valid_malignant_indices[0]

# Se genera una explicación local usando LIME para la instancia seleccionada
# 'num_features=19' indica cuántas características incluir en la explicación
exp_malignant = explainer.explain_instance(X_test[i_malignant],
                                           best_model.predict_proba,
                                           num_features=19)

# Visualización de la explicación para la instancia maligna
exp_malignant.as_pyplot_figure()
plt.title('LIME Explanation for Malignant')
plt.show()

# === Explicación de una instancia de la clase "Benigno" ===

# Se filtran los índices para asegurarse de que estén dentro del rango válido de X_test
valid_benign_indices = benign_indices[benign_indices < len(X_test)]

# Se selecciona la primera instancia válida de la clase "Benigno"
i_benign = valid_benign_indices[0]

# Se genera una explicación local usando LIME para la instancia seleccionada
exp_benign = explainer.explain_instance(X_test[i_benign],
                                        best_model.predict_proba,
                                        num_features=19)

# Visualización de la explicación para la instancia benigna
exp_benign.as_pyplot_figure()
plt.title('LIME Explanation for Benign')
plt.show()